{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network from Scratch\n",
    "## Neural Network implemented from scratch using linear algebra library\n",
    "## Adjustable layer count/layer size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import hashlib\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def fetch(url):\n",
    "\n",
    "    fp = os.path.join(\"/tmp\", hashlib.md5(url.encode('utf-8')).hexdigest())\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp, \"rb\") as f:\n",
    "            dat = f.read()\n",
    "    else:\n",
    "        with open(fp, \"wb\") as f:\n",
    "            dat = requests.get(url).content\n",
    "            f.write(dat)\n",
    "    return np.frombuffer(gzip.decompress(dat), dtype=np.uint8).copy()\n",
    "\n",
    "\n",
    "X_train = fetch(\n",
    "    \"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
    "Y_train = fetch(\n",
    "    \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")[8:]\n",
    "X_test = fetch(\n",
    "    \"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
    "Y_test = fetch(\n",
    "    \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\")[8:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different methods of initialising weights/biases\n",
    "#gaussian works poorly for more than 2 layers.\n",
    "#fan_init seems to work best for this reason\n",
    "def gaussian_init(m, h):\n",
    "    ret = np.random.uniform(-1., 1., size=(m, h))/np.sqrt(m*h)\n",
    "    return ret.astype(np.float32)\n",
    "\n",
    "def he_init(m, h):\n",
    "    ret = np.random.randn(m,h)*np.sqrt(2/h)\n",
    "    return ret.astype(np.float32)\n",
    "\n",
    "def fan_init(m, h):\n",
    "    ret = np.random.randn(m,h)*np.sqrt(12/(2*m*h))\n",
    "    return ret.astype(np.float32)\n",
    "#helper functions to initialise paramteres(weights and biases)\n",
    "def get_layer_sizes(input_size,hidden_layers,output_size):\n",
    "    layer_sizes = [input_size]+hidden_layers+[output_size]\n",
    "    return layer_sizes\n",
    "\n",
    "def param_init(layer_sizes,layer_init):\n",
    "    params=[[],[]]\n",
    "    for i in range(1,len(layer_sizes)):\n",
    "        params[0].append(layer_init(1,layer_sizes[i]))\n",
    "        params[1].append(layer_init(layer_sizes[i-1],layer_sizes[i]))\n",
    "    return params\n",
    "def get_params(input_size,hidden_layers,output_size,layer_init):\n",
    "    layer_sizes = get_layer_sizes(input_size,hidden_layers,output_size)\n",
    "    params = param_init(layer_sizes,layer_init)\n",
    "    return params\n",
    "#gives output of neural network for a given input\n",
    "def forward(x,params):\n",
    "    for i in range(len(params[0])-1):\n",
    "        x = x.dot(params[1][i])+params[0][i]\n",
    "        x = np.maximum(x,0)\n",
    "    \n",
    "    x = x.dot(params[1][-1])+params[0][-1]\n",
    "    return x\n",
    "#tests neural network on test data\n",
    "def numpy_eval(params):\n",
    "    Y_test_preds_out = forward(X_test.reshape((-1, 28*28)),params)\n",
    "    Y_test_preds = np.argmax(Y_test_preds_out, axis=1)\n",
    "    return (Y_test == Y_test_preds).mean()\n",
    "#activation function & derivative\n",
    "def sigmoid(x):\n",
    "    x=np.clip(x,-500,500)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "#loss function and derivative\n",
    "def mse(targets, predictions):\n",
    "    mse = ((targets - predictions)**2).mean(axis=0)\n",
    "    return mse\n",
    "\n",
    "def mse_derivative(targets, predictions):\n",
    "    return 2*(predictions-targets)/predictions.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(x,y,params):\n",
    "    # training\n",
    "    out = np.zeros((len(y), 10), np.float32)\n",
    "    out[range(out.shape[0]), y] = 1\n",
    "\n",
    "    input_layer = [x]\n",
    "    output_layer = []\n",
    "    d_output_layer = []\n",
    "    d_input_layer = []\n",
    "    \n",
    "    # forward pass layer 0-x\n",
    "    \n",
    "    for i in range(len(params[0])-1):\n",
    "        output_layer.append(input_layer[-1].dot(params[1][i]))\n",
    "        output_layer[-1] += params[0][i]\n",
    "        input_layer.append(np.maximum(output_layer[-1], 0))\n",
    "\n",
    "    # final layer forward pass\n",
    "    \n",
    "    output_layer.append(input_layer[-1].dot(params[1][-1]))\n",
    "    output_layer[-1] += params[0][-1]\n",
    "\n",
    "    final = output_layer[-1]\n",
    "    x_sigmoid = sigmoid(final)\n",
    "\n",
    "    x_mse = mse(out, x_sigmoid)\n",
    "\n",
    "    # backward pass\n",
    "    # tricky\n",
    "    #basic idea is to use chain rule to calculate d(loss function)/dx for each parameter dx\n",
    "    #d(loss function)/dx is how a small change in x affects loss function.\n",
    "    #we calculate dl/d(input) and dl/d(output) of each layer in order to do this.\n",
    "  \n",
    "    d_mse = mse_derivative(out, x_sigmoid)\n",
    "    d_sigmoid = np.empty_like(final)\n",
    "\n",
    "    # caluculate derivatives for each sigmoiod\n",
    "    for q in range(d_mse.shape[0]):\n",
    "\n",
    "        d_sigmoid[q] = sigmoid_derivative(final[q])*d_mse[q]\n",
    "\n",
    "    # calculate derivatives for the output & input of each layer\n",
    "    d_output_layer.insert(0, d_sigmoid)\n",
    "\n",
    "    for i in range(len(params[0])-1):\n",
    "        \n",
    "        d_input_layer.insert(\n",
    "            0, d_output_layer[-(i+1)].dot(params[1][-(i+1)].T))\n",
    "        \n",
    "        d_output_layer.insert(\n",
    "            0, (input_layer[-(i+1)] > 0).astype(np.float32)*d_input_layer[-(i+1)])\n",
    "\n",
    "    d_params = [[np.sum(d_output_layer[i], axis=0) for i in range(len(d_output_layer))],\n",
    "                [input_layer[i].T.dot(d_output_layer[i]) for i in range(len(d_output_layer))]]\n",
    "\n",
    "    return x_mse, final, d_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params,hyperparams):\n",
    "    losses, accuracies = [], []\n",
    "    lr,BS,iterations = hyperparams\n",
    "    for i in (t := trange(iterations)):\n",
    "        samp = np.random.randint(0, X_train.shape[0], size=(BS))\n",
    "        X = X_train[samp].reshape((-1, 28*28))\n",
    "\n",
    "        Y = Y_train[samp]\n",
    "        \n",
    "        x_loss, final_layer,d_params = forward_backward(X, Y,params)\n",
    "\n",
    "        cat = np.argmax(final_layer, axis=1)\n",
    "        accuracy = (cat == Y).mean()\n",
    "        \n",
    "        #update weights and biases by some constant (learning rate) times their gradient\n",
    "        #gradient calculated above.\n",
    "        for i in range(len(params)):\n",
    "            for j in range(len(params[0])):\n",
    "                params[i][j]-=lr*d_params[i][j]\n",
    "        \n",
    "        loss = x_loss.mean()\n",
    "        losses.append(loss)\n",
    "        accuracies.append(accuracy)\n",
    "        t.set_description(f\"loss {loss:.3f} accuracy {accuracy:.3f}\")\n",
    "\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.plot(losses)\n",
    "    plt.plot(accuracies)\n",
    "    print(sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_139775/3640902875.py:46: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "loss 0.387 accuracy 0.117:  24%|██▍       | 239/1000 [00:07<00:24, 31.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m#two iterations of 1000 batches\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     train(params,hyperparams)\n\u001b[1;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy on test data is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(numpy_eval(params),\u001b[39m4\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[39m#decrease learning rate as model trains.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m#at start of training, we need to change parameters a lot.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39m#then towards the end it is more finetuning.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[156], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, hyperparams)\u001b[0m\n\u001b[1;32m      6\u001b[0m X \u001b[39m=\u001b[39m X_train[samp]\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m))\n\u001b[1;32m      8\u001b[0m Y \u001b[39m=\u001b[39m Y_train[samp]\n\u001b[0;32m---> 10\u001b[0m x_loss, final_layer,d_params \u001b[39m=\u001b[39m forward_backward(X, Y,params)\n\u001b[1;32m     12\u001b[0m cat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(final_layer, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m accuracy \u001b[39m=\u001b[39m (cat \u001b[39m==\u001b[39m Y)\u001b[39m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[155], line 48\u001b[0m, in \u001b[0;36mforward_backward\u001b[0;34m(x, y, params)\u001b[0m\n\u001b[1;32m     43\u001b[0m d_output_layer\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, d_sigmoid)\n\u001b[1;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(params[\u001b[39m0\u001b[39m])\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     47\u001b[0m     d_input_layer\u001b[39m.\u001b[39minsert(\n\u001b[0;32m---> 48\u001b[0m         \u001b[39m0\u001b[39m, d_output_layer[\u001b[39m-\u001b[39;49m(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)]\u001b[39m.\u001b[39;49mdot(params[\u001b[39m1\u001b[39;49m][\u001b[39m-\u001b[39;49m(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)]\u001b[39m.\u001b[39;49mT))\n\u001b[1;32m     50\u001b[0m     d_output_layer\u001b[39m.\u001b[39minsert(\n\u001b[1;32m     51\u001b[0m         \u001b[39m0\u001b[39m, (input_layer[\u001b[39m-\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\u001b[39m*\u001b[39md_input_layer[\u001b[39m-\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[1;32m     53\u001b[0m d_params \u001b[39m=\u001b[39m [[np\u001b[39m.\u001b[39msum(d_output_layer[i], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(d_output_layer))],\n\u001b[1;32m     54\u001b[0m             [input_layer[i]\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(d_output_layer[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(d_output_layer))]]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#input and output are fixed for this training data.\n",
    "#hidden sizes can be changed.\n",
    "hidden_sizes = [512,128]\n",
    "#64x64 pixels = 784 pixels when flattened out\n",
    "input_size = 784\n",
    "#one output neuron for each digit 0-9\n",
    "output_size = 10\n",
    "np.random.seed(77)\n",
    "\n",
    "params = get_params(input_size,hidden_sizes,output_size,he_init)\n",
    "\n",
    "#batch size\n",
    "BS = 128\n",
    "#learning rate hard to get right\n",
    "lr = 0.00001\n",
    "iterations=1000\n",
    "\n",
    "#hyper parameters control how parameters are trained.\n",
    "hyperparams = [lr,BS,iterations]\n",
    "\n",
    "#two iterations of 1000 batches\n",
    "for i in range(5):\n",
    "    train(params,hyperparams)\n",
    "    \n",
    "    print(f'accuracy on test data is {round(numpy_eval(params),4)*100}%')\n",
    "    #decrease learning rate as model trains.\n",
    "    #at start of training, we need to change parameters a lot.\n",
    "    #then towards the end it is more finetuning.\n",
    "    hyperparams[0]*=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test data is 96.19%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'accuracy on test data is {round(numpy_eval(params),4)*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value is : 0, this is correct!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samp = np.random.randint(0, X_test.shape[0], size=(1))\n",
    "img = X_test[samp]\n",
    "y = np.argmax(forward(img.reshape((-1,28*28)),params))\n",
    "print(f'Predicted value is : {y}, this is {[\"wrong.\",\"correct!\"][int(Y_test[samp][0]==y)]}')\n",
    "plt.imshow(img[0], interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
